{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d177a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l_torch import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67b7477d-c6dc-4840-b852-b04588b29811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X: torch.Tensor, K: torch.Tensor):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros(X.shape[0] - h + 1, X.shape[1] - w + 1)\n",
    "    # Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y\n",
    "    \n",
    "\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "    \"\"\"A convolution layer\"\"\"\n",
    "    def __init__(self, kernel_size: int):\n",
    "        super.__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        return corr2d(X, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1352cad3-2726-4a61-b9ff-0a335892f5af",
   "metadata": {},
   "source": [
    "Some Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ff50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80bac0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab08cd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e783a44",
   "metadata": {},
   "source": [
    "Helper function for performing convolution, making sure everything fits dimension-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c17a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1) indicates that batch size and the number of channels are both 1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # Strip the first two dimensions: examples and channels\n",
    "    return Y.reshape(Y.shape[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fd5f05",
   "metadata": {},
   "source": [
    "Example on **Padding and Stride**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88d8d24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 row and column is padded on either side, so a total of 2 rows or columns\n",
    "# are added\n",
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ce7194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a convolution kernel with height 5 and width 3. The padding on either\n",
    "# side of the height and width are 2 and 1, respectively\n",
    "conv2d = nn.LazyConv2d(1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acd5addb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685083c8",
   "metadata": {},
   "source": [
    "What if we have more channels?\n",
    "A: Then our kernel needs multiple input channels as well (same number of channels as the input data);\n",
    "We sum up the cross-correlated results over all of the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "542efc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    # Iterate through the 0th dimension (channel) of K first, then add them up\n",
    "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f191a",
   "metadata": {},
   "source": [
    "With multiple output channels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbfbba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # Iterate through the 0th dimension of K, and each time, perform\n",
    "    # cross-correlation operations with input X. All of the results are\n",
    "    # stacked together\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1319ecd9",
   "metadata": {},
   "source": [
    "Sometimes using a kernel of size 1x1 for each channel is useful, as it connects infomation across all of the output channels from the previous layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b800a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    # Matrix multiplication in the fully connected layer\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ac4f7",
   "metadata": {},
   "source": [
    "Let's move on to **Pooling**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f6099",
   "metadata": {},
   "source": [
    "Forward propagation of pooling layer (max or avg pooling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fabaeab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X: torch.Tensor, pool_size: tuple[int], mode: str = 'max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i:i + p_h, j:j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i:i + p_h, j:j + p_w].mean()\n",
    "    return Y \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a614152e",
   "metadata": {},
   "source": [
    "Now we have everything to assemble a fully-functional CNN (LeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867dde62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed9d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe352ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
